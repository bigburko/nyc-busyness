{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML for foot traffic score\n",
    "Prediction for the foot traffic score using the Yellow Taxi Data from 2020 - 2023 to predict the foot traffic score during daytimes (morning, afternoon, evening, night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine foot traffic scores from 2020 - 2023 with subway access scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "all_future_foot_scores = pd.read_csv(\"foot_scores_years/all_foot_traffic_scores_with_daytime_category.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>daytime_category</th>\n",
       "      <th>daily_pickup_count</th>\n",
       "      <th>daily_dropoff_count</th>\n",
       "      <th>daily_dropoff_count_scaled</th>\n",
       "      <th>daily_pickup_count_scaled</th>\n",
       "      <th>daily_foot_traffic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.067390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>31.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.252624</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.192470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>evening</td>\n",
       "      <td>363.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>2.254906</td>\n",
       "      <td>1.610198</td>\n",
       "      <td>2.061494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>morning</td>\n",
       "      <td>10.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.158147</td>\n",
       "      <td>1.016810</td>\n",
       "      <td>1.115746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>81.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.127339</td>\n",
       "      <td>1.136160</td>\n",
       "      <td>1.129985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trip_date  LocationID daytime_category  daily_pickup_count  \\\n",
       "0  2020-01-01           4          morning                31.0   \n",
       "1  2020-01-01           4        afternoon                31.0   \n",
       "2  2020-01-01           4          evening               363.0   \n",
       "3  2020-01-01          12          morning                10.0   \n",
       "4  2020-01-01          12        afternoon                81.0   \n",
       "\n",
       "   daily_dropoff_count  daily_dropoff_count_scaled  daily_pickup_count_scaled  \\\n",
       "0                 36.0                    1.073939                   1.052111   \n",
       "1                123.0                    1.252624                   1.052111   \n",
       "2                611.0                    2.254906                   1.610198   \n",
       "3                 77.0                    1.158147                   1.016810   \n",
       "4                 62.0                    1.127339                   1.136160   \n",
       "\n",
       "   daily_foot_traffic_score  \n",
       "0                  1.067390  \n",
       "1                  1.192470  \n",
       "2                  2.061494  \n",
       "3                  1.115746  \n",
       "4                  1.129985  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_future_foot_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load geojson\n",
    "import json\n",
    "with open(r'..\\census tract geofiles\\manhattan_census_tracts.geojson', 'r') as f:\n",
    "    geojson = json.load(f)\n",
    "    \n",
    "geoids = [feature['properties']['GEOID'] for feature in geojson['features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping 67 LocationIDs to 310 GEOIDs\n",
      "Approximately 4 census tracts per LocationID\n",
      "Created 310 rows for GEOID mapping\n"
     ]
    }
   ],
   "source": [
    "# Map LocationIDs to GEOIDs\n",
    "result_rows = []\n",
    "locations = sorted(all_future_foot_scores['LocationID'].unique())\n",
    "tracts_per_location = len(geoids) // len(locations)\n",
    "\n",
    "print(f\"Mapping {len(locations)} LocationIDs to {len(geoids)} GEOIDs\")\n",
    "print(f\"Approximately {tracts_per_location} census tracts per LocationID\")\n",
    "\n",
    "geoid_index = 0\n",
    "for i, location_id in enumerate(locations):\n",
    "    location_data = all_future_foot_scores[all_future_foot_scores['LocationID'] == location_id].iloc[0]\n",
    "    num_geoids = tracts_per_location + (1 if i < len(geoids) % len(locations) else 0)\n",
    "    \n",
    "    for j in range(num_geoids):\n",
    "        if geoid_index < len(geoids):\n",
    "            row = {'GEOID': geoids[geoid_index]}\n",
    "            for col in all_future_foot_scores.columns:\n",
    "                if col != 'LocationID':\n",
    "                    row[col] = location_data[col]\n",
    "            result_rows.append(row)\n",
    "            geoid_index += 1\n",
    "            \n",
    "print(f\"Created {len(result_rows)} rows for GEOID mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>trip_date</th>\n",
       "      <th>daytime_category</th>\n",
       "      <th>daily_pickup_count</th>\n",
       "      <th>daily_dropoff_count</th>\n",
       "      <th>daily_dropoff_count_scaled</th>\n",
       "      <th>daily_pickup_count_scaled</th>\n",
       "      <th>daily_foot_traffic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36061000100</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36061001401</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36061001402</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36061001800</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36061002201</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GEOID   trip_date daytime_category  daily_pickup_count  \\\n",
       "0  36061000100  2020-01-01          morning                31.0   \n",
       "1  36061001401  2020-01-01          morning                31.0   \n",
       "2  36061001402  2020-01-01          morning                31.0   \n",
       "3  36061001800  2020-01-01          morning                31.0   \n",
       "4  36061002201  2020-01-01          morning                31.0   \n",
       "\n",
       "   daily_dropoff_count  daily_dropoff_count_scaled  daily_pickup_count_scaled  \\\n",
       "0                 36.0                    1.073939                   1.052111   \n",
       "1                 36.0                    1.073939                   1.052111   \n",
       "2                 36.0                    1.073939                   1.052111   \n",
       "3                 36.0                    1.073939                   1.052111   \n",
       "4                 36.0                    1.073939                   1.052111   \n",
       "\n",
       "   daily_foot_traffic_score  \n",
       "0                   1.06739  \n",
       "1                   1.06739  \n",
       "2                   1.06739  \n",
       "3                   1.06739  \n",
       "4                   1.06739  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save to df\n",
    "mapped_df = pd.DataFrame(result_rows)\n",
    "mapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>subway_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36061000100</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36061001401</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36061001402</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36061001800</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36061002201</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GEOID  subway_score\n",
       "0  36061000100          0.00\n",
       "1  36061001401          2.17\n",
       "2  36061001402          2.02\n",
       "3  36061001800          2.65\n",
       "4  36061002201          1.67"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load subway scores and merge with future foot traffic\n",
    "subway_scores_df = pd.read_csv(\"subway_score_by_tract.csv\")\n",
    "subway_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge future foot scores with subway scores based on GEOIDs\n",
    "combined_df = pd.merge(mapped_df, subway_scores_df, on=\"GEOID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>trip_date</th>\n",
       "      <th>daytime_category</th>\n",
       "      <th>daily_pickup_count</th>\n",
       "      <th>daily_dropoff_count</th>\n",
       "      <th>daily_dropoff_count_scaled</th>\n",
       "      <th>daily_pickup_count_scaled</th>\n",
       "      <th>daily_foot_traffic_score</th>\n",
       "      <th>subway_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36061000100</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36061001401</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36061001402</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36061001800</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36061002201</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.06739</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GEOID   trip_date daytime_category  daily_pickup_count  \\\n",
       "0  36061000100  2020-01-01          morning                31.0   \n",
       "1  36061001401  2020-01-01          morning                31.0   \n",
       "2  36061001402  2020-01-01          morning                31.0   \n",
       "3  36061001800  2020-01-01          morning                31.0   \n",
       "4  36061002201  2020-01-01          morning                31.0   \n",
       "\n",
       "   daily_dropoff_count  daily_dropoff_count_scaled  daily_pickup_count_scaled  \\\n",
       "0                 36.0                    1.073939                   1.052111   \n",
       "1                 36.0                    1.073939                   1.052111   \n",
       "2                 36.0                    1.073939                   1.052111   \n",
       "3                 36.0                    1.073939                   1.052111   \n",
       "4                 36.0                    1.073939                   1.052111   \n",
       "\n",
       "   daily_foot_traffic_score  subway_score  \n",
       "0                   1.06739          0.00  \n",
       "1                   1.06739          2.17  \n",
       "2                   1.06739          2.02  \n",
       "3                   1.06739          2.65  \n",
       "4                   1.06739          1.67  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute combined score (65% foot traffic, 35% subway access)\n",
    "combined_df[\"combined_score\"] = (\n",
    "    0.65 * combined_df[\"daily_foot_traffic_score\"] +\n",
    "    0.35 * combined_df[\"subway_score\"]\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save combined future foot scores\n",
    "combined_df.to_csv(\"combined_future_foot_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "geoid_means = combined_df.groupby('GEOID')['combined_score'].mean()\n",
    "combined_df['GEOID_encoded'] = combined_df['GEOID'].map(geoid_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['pickup_x_dayofweek'] = combined_df['daily_pickup_count_scaled'] * combined_df['day_of_week']\n",
    "combined_df['dropoff_x_dayofweek'] = combined_df['daily_dropoff_count_scaled'] * combined_df['day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessor Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "combined_df['trip_date'] = pd.to_datetime(combined_df['trip_date'])\n",
    "combined_df['year'] = combined_df['trip_date'].dt.year\n",
    "combined_df['month'] = combined_df['trip_date'].dt.month\n",
    "combined_df['day_of_week'] = combined_df['trip_date'].dt.dayofweek\n",
    "\n",
    "features = ['GEOID_encoded','daytime_category', 'daily_pickup_count_scaled', 'dropoff_x_dayofweek',\n",
    "            'pickup_x_dayofweek','daily_dropoff_count_scaled', 'year', 'month', 'day_of_week']\n",
    "target = 'combined_score'\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df[target]\n",
    "\n",
    "categorical_features = ['GEOID_encoded','daytime_category', 'year', 'month', 'day_of_week']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # 'remainder' will have no effect here as there are no numerical features other than what's encoded\n",
    ")\n",
    "\n",
    "print(\"\\n--- Preprocessor Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Random Train-Test Split ---\n",
      "Train set shape: (248, 9), (248,)\n",
      "Test set shape: (62, 9), (62,)\n",
      "\n",
      "--- Training the Linear Regression model ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation (on random 20% test data) ---\n",
      "Mean Absolute Error (MAE): 0.1152\n",
      "R-squared (R2): 0.6465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Using a standard random train-test split instead.\n",
    "print(\"\\n--- Performing Random Train-Test Split ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 20% for testing\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "model_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', LinearRegression())])\n",
    "\n",
    "print(\"\\n--- Training the Linear Regression model ---\")\n",
    "model_lr.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred = model_lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- Model Evaluation (on random 20% test data) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the RandomForestRegressor model ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation (on random 20% test data) ---\n",
      "Mean Absolute Error (MAE): 0.1393\n",
      "R-squared (R2): 0.6118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model_lr = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Add interaction & squared terms\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "print(\"\\n--- Training the RandomForestRegressor model ---\")\n",
    "model_lr.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred = model_lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- Model Evaluation (on random 20% test data) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Random Train-Test Split ---\n",
      "Train set shape: (248, 9), (248,)\n",
      "Test set shape: (62, 9), (62,)\n",
      "\n",
      "--- Training the RandomForestRegressor model ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation (on random 20% test data) ---\n",
      "Mean Absolute Error (MAE): 0.2689\n",
      "R-squared (R2): 0.3733\n"
     ]
    }
   ],
   "source": [
    "# Using a standard random train-test split instead.\n",
    "print(\"\\n--- Performing Random Train-Test Split ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 20% for testing\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "model_randomforest = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])\n",
    "\n",
    "print(\"\\n--- Training the RandomForestRegressor model ---\")\n",
    "model_randomforest.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred = model_randomforest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- Model Evaluation (on random 20% test data) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*HistGradientBoostingRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessor Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "combined_df['trip_date'] = pd.to_datetime(combined_df['trip_date'])\n",
    "combined_df['year'] = combined_df['trip_date'].dt.year\n",
    "combined_df['month'] = combined_df['trip_date'].dt.month\n",
    "combined_df['day_of_week'] = combined_df['trip_date'].dt.dayofweek\n",
    "\n",
    "features = ['GEOID_encoded','daytime_category', 'daily_pickup_count_scaled', 'dropoff_x_dayofweek',\n",
    "            'pickup_x_dayofweek','daily_dropoff_count_scaled', 'year', 'month', 'day_of_week']\n",
    "target = 'combined_score'\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df[target]\n",
    "\n",
    "categorical_features = ['GEOID_encoded','daytime_category', 'year', 'month', 'day_of_week']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "print(\"\\n--- Preprocessor Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Random Train-Test Split (no 'year' column for chronological split) ---\n",
      "Train set shape: (248, 9), (248,)\n",
      "Test set shape: (62, 9), (62,)\n",
      "\n",
      "--- Training the HistGradientBoostingRegressor model ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation (on random 20% test data) ---\n",
      "Mean Absolute Error (MAE): 0.3592\n",
      "R-squared (R2): 0.1412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Using a standard random train-test split instead.\n",
    "print(\"\\n--- Performing Random Train-Test Split (no 'year' column for chronological split) ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 20% for testing\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "model_histgrbregressor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', HistGradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "print(\"\\n--- Training the HistGradientBoostingRegressor model ---\")\n",
    "model_histgrbregressor.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred = model_histgrbregressor.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- Model Evaluation (on random 20% test data) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comparing all models with XGBRegressor (from xgboost) and LGBMRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training RandomForest ---\n",
      "RandomForest → R²: 0.3733, MAE: 0.2688\n",
      "\n",
      "--- Training HistGradientBoosting ---\n",
      "HistGradientBoosting → R²: 0.1412, MAE: 0.3592\n",
      "\n",
      "--- Training XGBoost ---\n",
      "XGBoost → R²: 0.4014, MAE: 0.2858\n",
      "\n",
      "--- Training LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 248, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 1.647097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM → R²: 0.1429, MAE: 0.3586\n",
      "\n",
      "--- Training DecisionTree ---\n",
      "DecisionTree → R²: 0.1494, MAE: 0.2732\n",
      "\n",
      "--- Training LinearRegression ---\n",
      "LinearRegression → R²: 0.6465, MAE: 0.1152\n",
      "\n",
      "--- Training RidgeRegression ---\n",
      "RidgeRegression → R²: 0.5338, MAE: 0.2269\n",
      "\n",
      "--- Training KNN ---\n",
      "KNN → R²: 0.2169, MAE: 0.3034\n",
      "\n",
      "--- Training SVR ---\n",
      "SVR → R²: 0.2656, MAE: 0.2877\n",
      "\n",
      "--- Training GradientBoosting ---\n",
      "GradientBoosting → R²: 0.3787, MAE: 0.3021\n",
      "\n",
      "--- Model Comparison Summary ---\n",
      "RandomForest           | R²: 0.3733 | MAE: 0.2688\n",
      "HistGradientBoosting   | R²: 0.1412 | MAE: 0.3592\n",
      "XGBoost                | R²: 0.4014 | MAE: 0.2858\n",
      "LightGBM               | R²: 0.1429 | MAE: 0.3586\n",
      "DecisionTree           | R²: 0.1494 | MAE: 0.2732\n",
      "LinearRegression       | R²: 0.6465 | MAE: 0.1152\n",
      "RidgeRegression        | R²: 0.5338 | MAE: 0.2269\n",
      "KNN                    | R²: 0.2169 | MAE: 0.3034\n",
      "SVR                    | R²: 0.2656 | MAE: 0.2877\n",
      "GradientBoosting       | R²: 0.3787 | MAE: 0.3021\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# --- Train-test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Preprocessing Pipeline ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# --- Models to Compare ---\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RidgeRegression\": Ridge(alpha=1.0),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"SVR\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "\n",
    "}\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = []\n",
    "\n",
    "for name, regressor in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    results.append((name, r2, mae))\n",
    "    print(f\"{name} → R²: {r2:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"\\n--- Model Comparison Summary ---\")\n",
    "for name, r2, mae in results:\n",
    "    print(f\"{name.ljust(22)} | R²: {r2:.4f} | MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction for 2024, 2025, 2026 aand 2027 using RandomForest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_date  LocationID daytime_category  predicted_foot_traffic_score\n",
      "0 2025-01-01           4          morning                      1.067397\n",
      "1 2025-01-01           4        afternoon                      1.192657\n",
      "2 2025-01-01           4          evening                      2.060485\n",
      "3 2025-01-01          12          morning                      1.115753\n",
      "4 2025-01-01          12        afternoon                      1.130004\n"
     ]
    }
   ],
   "source": [
    "# Copy base data\n",
    "base = combined_df.copy()\n",
    "\n",
    "# Get original date components\n",
    "base['trip_date'] = pd.to_datetime(base['trip_date'])\n",
    "base['month'] = base['trip_date'].dt.month\n",
    "base['day_of_week'] = base['trip_date'].dt.dayofweek\n",
    "\n",
    "# Create future set\n",
    "future_years = [2025, 2026, 2027]\n",
    "future_foot_traffic = pd.DataFrame()\n",
    "\n",
    "def safe_replace_year_or_none(date_obj, new_year):\n",
    "    try:\n",
    "        return date_obj.replace(year=new_year)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "for year in future_years:\n",
    "    temp = base.copy()\n",
    "    temp['year'] = year\n",
    "    temp['trip_date'] = temp['trip_date'].apply(lambda d: safe_replace_year_or_none(d, year))\n",
    "    temp = temp.dropna(subset=['trip_date'])\n",
    "    future_foot_traffic = pd.concat([future_foot_traffic, temp], ignore_index=True)\n",
    "\n",
    "# Features used in model\n",
    "features = ['LocationID', 'daytime_category', 'daily_pickup_count_scaled', \n",
    "            'daily_dropoff_count_scaled', 'year', 'month', 'day_of_week']\n",
    "\n",
    "X_future = future_foot_traffic[features]\n",
    "\n",
    "# Predict\n",
    "future_foot_traffic['predicted_foot_traffic_score'] = model_randomforest.predict(X_future)\n",
    "\n",
    "# View\n",
    "print(future_foot_traffic[['trip_date', 'LocationID', 'daytime_category', 'predicted_foot_traffic_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>daytime_category</th>\n",
       "      <th>daily_pickup_count</th>\n",
       "      <th>daily_dropoff_count</th>\n",
       "      <th>daily_dropoff_count_scaled</th>\n",
       "      <th>daily_pickup_count_scaled</th>\n",
       "      <th>daily_foot_traffic_score</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>predicted_foot_traffic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>morning</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.073939</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.067390</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.067397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>31.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.252624</td>\n",
       "      <td>1.052111</td>\n",
       "      <td>1.192470</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.192657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>evening</td>\n",
       "      <td>363.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>2.254906</td>\n",
       "      <td>1.610198</td>\n",
       "      <td>2.061494</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.060485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>morning</td>\n",
       "      <td>10.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.158147</td>\n",
       "      <td>1.016810</td>\n",
       "      <td>1.115746</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.115753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>81.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.127339</td>\n",
       "      <td>1.136160</td>\n",
       "      <td>1.129985</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.130004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_date  LocationID daytime_category  daily_pickup_count  \\\n",
       "0 2025-01-01           4          morning                31.0   \n",
       "1 2025-01-01           4        afternoon                31.0   \n",
       "2 2025-01-01           4          evening               363.0   \n",
       "3 2025-01-01          12          morning                10.0   \n",
       "4 2025-01-01          12        afternoon                81.0   \n",
       "\n",
       "   daily_dropoff_count  daily_dropoff_count_scaled  daily_pickup_count_scaled  \\\n",
       "0                 36.0                    1.073939                   1.052111   \n",
       "1                123.0                    1.252624                   1.052111   \n",
       "2                611.0                    2.254906                   1.610198   \n",
       "3                 77.0                    1.158147                   1.016810   \n",
       "4                 62.0                    1.127339                   1.136160   \n",
       "\n",
       "   daily_foot_traffic_score  year  month  day_of_week  \\\n",
       "0                  1.067390  2025      1            2   \n",
       "1                  1.192470  2025      1            2   \n",
       "2                  2.061494  2025      1            2   \n",
       "3                  1.115746  2025      1            2   \n",
       "4                  1.129985  2025      1            2   \n",
       "\n",
       "   predicted_foot_traffic_score  \n",
       "0                      1.067397  \n",
       "1                      1.192657  \n",
       "2                      2.060485  \n",
       "3                      1.115753  \n",
       "4                      1.130004  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_foot_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv\n",
    "future_foot_traffic.to_csv('future_foot_traffic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
